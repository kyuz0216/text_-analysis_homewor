{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題1：ドキュメントの類似度を計算する \n",
    "以下の要件を満たすプログラムを作成  \n",
    "・10個以上の文書を対象  \n",
    "・2種類以上の文書表現手法  \n",
    "・2種類以上の距離尺度  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 対象となる10個以上の文書を取得\n",
    "著作権の切れた青空文庫から１０個の文書を取得  \n",
    "doc1 : 夏目漱石「こころ」上の一  \n",
    "doc2 : 夏目漱石「こころ」上の二  \n",
    "doc3 : 夏目漱石「こころ」上の三  \n",
    "doc4 : 宮沢賢治「銀河鉄道の夜」一  \n",
    "doc5 : 宮沢賢治「銀河鉄道の夜」二  \n",
    "doc6 : 宮沢賢治「銀河鉄道の夜」三  \n",
    "doc7 : 夏目漱石「坊ちゃん」一(途中まで)   \n",
    "doc8 : 夏目漱石「坊ちゃん」二(途中まで)  \n",
    "doc9 : 夏目漱石「坊ちゃん」三(途中まで)  \n",
    "doc10 : フランツカフカ「変身」一(途中まで)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "　私《わたくし》はその人を常に先生と呼んでいた。だからここでもただ先生と書くだけで本名は打ち明けない。これは世間を憚《はば》かる遠慮というよりも、その方が私にとって自然だからである。私はその人の記憶を呼び起すごとに、すぐ「先生」といいたくなる。筆を執《と》っても心持は同じ事である。よそよそしい頭文字《かしらもじ》などはとても使う気にならない。\n",
      "　私が先生と知り合いになったのは鎌倉《かまくら》である。その時私はまだ若々しい書生であった。暑中休暇を利用して海水浴に行った友達からぜひ来いという端書《はがき》を受け取ったので、私は多少の金を工面《くめん》して、出掛ける事にした。私は金の工面に二《に》、三日《さんち》を費やした。ところが私が鎌倉に着いて三日と経《た》たないうちに、私を呼び寄せた友達は、急に国元から帰れという電報を受け取った。電報には母が病気だからと断ってあったけれども友達はそれを信じなかった。友達はかねてから国元にいる親たちに勧《すす》まない結婚を強《し》いられていた。彼は現代の習慣からいうと結婚するにはあまり年が若過ぎた。それに肝心《かんじん》の当人が気に入らなかった。それで夏休みに当然帰るべきところを、わざと避けて東京の近くで遊んでいたのである。彼は電報を私に見せてどうしようと相談をした。私にはどうしていいか分らなかった。けれども実際彼の母が病気であるとすれば彼は固《もと》より帰るべきはずであった。それで彼はとうとう帰る事になった。せっかく来た私は一人取り残された。\n",
      "　学校の授業が始まるにはまだ大分《だいぶ》日数《ひかず》があるので鎌倉におってもよし、帰ってもよいという境遇にいた私は、当分元の宿に留《と》まる覚悟をした。友達は中国のある資産家の息子《むすこ》で金に不自由のない男であったけれども、学校が学校なのと年が年なので、生活の程度は私とそう変りもしなかった。したがって一人《ひとり》ぼっちになった私は別に恰好《かっこう》な宿を探す面倒ももたなかったのである。\n",
      "　宿は鎌倉でも辺鄙《へんぴ》な方角にあった。玉突《たまつ》きだのアイスクリームだのというハイカラなものには長い畷《なわて》を一つ越さなければ手が届かなかった。車で行っても二十銭は取られた。けれども個人の別荘はそこここにいくつでも建てられていた。それに海へはごく近いので海水浴をやるには至極便利な地位を占めていた。\n",
      "　私は毎日海へはいりに出掛けた。古い燻《くす》ぶり返った藁葺《わらぶき》の間《あいだ》を通り抜けて磯《いそ》へ下りると、この辺《へん》にこれほどの都会人種が住んでいるかと思うほど、避暑に来た男や女で砂の上が動いていた。ある時は海の中が銭湯《せんとう》のように黒い頭でごちゃごちゃしている事もあった。その中に知った人を一人ももたない私も、こういう賑《にぎ》やかな景色の中に裹《つつ》まれて、砂の上に寝《ね》そべってみたり、膝頭《ひざがしら》を波に打たしてそこいらを跳《は》ね廻《まわ》るのは愉快であった。\n",
      "　私は実に先生をこの雑沓《ざっとう》の間《あいだ》に見付け出したのである。その時海岸には掛茶屋《かけぢゃや》が二軒あった。私はふとした機会《はずみ》からその一軒の方に行き慣《な》れていた。長谷辺《はせへん》に大きな別荘を構えている人と違って、各自《めいめい》に専有の着換場《きがえば》を拵《こしら》えていないここいらの避暑客には、ぜひともこうした共同着換所といった風《ふう》なものが必要なのであった。彼らはここで茶を飲み、ここで休息する外《ほか》に、ここで海水着を洗濯させたり、ここで鹹《しお》はゆい身体《からだ》を清めたり、ここへ帽子や傘《かさ》を預けたりするのである。海水着を持たない私にも持物を盗まれる恐れはあったので、私は海へはいるたびにその茶屋へ一切《いっさい》を脱《ぬ》ぎ棄《す》てる事にしていた。\n"
     ]
    }
   ],
   "source": [
    "# データ読み込み\n",
    "doc_origin_list = []\n",
    "for i in range(1,11):\n",
    "    with open(\"./doc_dir/doc{}.txt\".format(i)) as f:\n",
    "        s = f.read()\n",
    "        doc_origin_list.append(s)\n",
    "\n",
    "print(doc_origin_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私はその人を常に先生と呼んでいただからここでもただ先生と書くだけで本名は打ち明けないこれは世間を憚かる遠慮というよりもその方が私にとって自然だからである私はその人の記憶を呼び起すごとにすぐ先生といいたくなる筆を執っても心持は同じ事であるよそよそしい頭文字などはとても使う気にならない私が先生と知り合いになったのは鎌倉であるその時私はまだ若々しい書生であった暑中休暇を利用して海水浴に行った友達からぜひ来いという端書を受け取ったので私は多少の金を工面して出掛ける事にした私は金の工面に二三日を費やしたところが私が鎌倉に着いて三日と経たないうちに私を呼び寄せた友達は急に国元から帰れという電報を受け取った電報には母が病気だからと断ってあったけれども友達はそれを信じなかった友達はかねてから国元にいる親たちに勧まない結婚を強いられていた彼は現代の習慣からいうと結婚するにはあまり年が若過ぎたそれに肝心の当人が気に入らなかったそれで夏休みに当然帰るべきところをわざと避けて東京の近くで遊んでいたのである彼は電報を私に見せてどうしようと相談をした私にはどうしていいか分らなかったけれども実際彼の母が病気であるとすれば彼は固より帰るべきはずであったそれで彼はとうとう帰る事になったせっかく来た私は一人取り残された学校の授業が始まるにはまだ大分日数があるので鎌倉におってもよし帰ってもよいという境遇にいた私は当分元の宿に留まる覚悟をした友達は中国のある資産家の息子で金に不自由のない男であったけれども学校が学校なのと年が年なので生活の程度は私とそう変りもしなかったしたがって一人ぼっちになった私は別に恰好な宿を探す面倒ももたなかったのである宿は鎌倉でも辺鄙な方角にあった玉突きだのアイスクリームだのというハイカラなものには長い畷を一つ越さなければ手が届かなかった車で行っても二十銭は取られたけれども個人の別荘はそこここにいくつでも建てられていたそれに海へはごく近いので海水浴をやるには至極便利な地位を占めていた私は毎日海へはいりに出掛けた古い燻ぶり返った藁葺の間を通り抜けて磯へ下りるとこの辺にこれほどの都会人種が住んでいるかと思うほど避暑に来た男や女で砂の上が動いていたある時は海の中が銭湯のように黒い頭でごちゃごちゃしている事もあったその中に知った人を一人ももたない私もこういう賑やかな景色の中に裹まれて砂の上に寝そべってみたり膝頭を波に打たしてそこいらを跳ね廻るのは愉快であった私は実に先生をこの雑沓の間に見付け出したのであるその時海岸には掛茶屋が二軒あった私はふとした機会からその一軒の方に行き慣れていた長谷辺に大きな別荘を構えている人と違って各自に専有の着換場を拵えていないここいらの避暑客にはぜひともこうした共同着換所といった風なものが必要なのであった彼らはここで茶を飲みここで休息する外にここで海水着を洗濯させたりここで鹹はゆい身体を清めたりここへ帽子や傘を預けたりするのである海水着を持たない私にも持物を盗まれる恐れはあったので私は海へはいるたびにその茶屋へ一切を脱ぎ棄てる事にしていた\n"
     ]
    }
   ],
   "source": [
    "def cleaning_text(text):\n",
    "    # 改行コードの削除\n",
    "    text = re.sub(r\"[\\r\\n]\", '', text)    \n",
    "    # 空欄の削除\n",
    "    text = re.sub(r\"[\\u3000 \\t]\", '', text)    \n",
    "    # 《》内を削除\n",
    "    text = re.sub(\"《[^》]+》\", '', text)\n",
    "    # 句読点などの記号を削除\n",
    "    text = re.sub(\"[。、―「」!?｜［］＃]\", '', text)\n",
    "    \n",
    "    return text\n",
    " \n",
    "doc_list = []\n",
    "for doc in doc_origin_list:\n",
    "    new_doc = cleaning_text(doc)\n",
    "    doc_list.append(new_doc)\n",
    "\n",
    "print(doc_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形態素解析\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "\n",
    "doc_token = []\n",
    "for doc in doc_list:\n",
    "    doc_token.append(t.tokenize(doc, wakati=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2種類以上の文書表現手法\n",
    "・集合ベース  \n",
    "文書を単語の集合として表現  \n",
    "・ベクトルベース  \n",
    "文書をベクトルとして表現  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 集合ベース"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形態素解析した文書を単語の集合に変換\n",
    "doc_set_list = []\n",
    "for i in range(10):\n",
    "    doc_set_list.append(set(doc_token[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 集合ベースの類似度\n",
    "Jaccard係数  \n",
    "Dice係数  \n",
    "Simpson係数  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import jaccard_distance\n",
    "import itertools\n",
    "\n",
    "cols = ['文書のペア', 'jaccard値']\n",
    "ans_jaccard_df = pd.DataFrame(index=[], columns=cols)\n",
    "#Jaccard係数を計算\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i < j:\n",
    "            tmp_name = \"doc\" + str(i+1) + \" と doc\" +  str(j+1)\n",
    "            record = pd.Series([tmp_name, 1 - jaccard_distance(doc_set_list[i], doc_set_list[j])], index=ans_jaccard_df.columns)\n",
    "            ans_jaccard_df = ans_jaccard_df.append(record, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>文書のペア</th>\n",
       "      <th>jaccard値</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc1 と doc3</td>\n",
       "      <td>0.180505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc1 と doc4</td>\n",
       "      <td>0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc1 と doc5</td>\n",
       "      <td>0.101562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc1 と doc6</td>\n",
       "      <td>0.119134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         文書のペア  jaccard値\n",
       "1  doc1 と doc3  0.180505\n",
       "2  doc1 と doc4  0.119792\n",
       "3  doc1 と doc5  0.101562\n",
       "4  doc1 と doc6  0.119134"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ５個表示\n",
    "ans_jaccard_df[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          文書のペア  jaccard値\n",
      "1   doc1 と doc3  0.180505\n",
      "30  doc5 と doc6  0.174946\n",
      "25  doc4 と doc6  0.170412\n",
      "42  doc8 と doc9  0.166998\n",
      "40  doc7 と doc9  0.161716\n",
      "0   doc1 と doc2  0.157993\n",
      "17  doc3 と doc4  0.156140\n",
      "39  doc7 と doc8  0.155786\n",
      "24  doc4 と doc5  0.154158\n"
     ]
    }
   ],
   "source": [
    "# jaccard値を大きい順にソート\n",
    "print(ans_jaccard_df.sort_values(by=\"jaccard値\",ascending=False)[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           文書のペア  jaccard値\n",
      "3    doc1 と doc5  0.101562\n",
      "31   doc5 と doc7  0.101911\n",
      "11   doc2 と doc5  0.107287\n",
      "16  doc2 と doc10  0.109375\n",
      "43  doc8 と doc10  0.109739\n",
      "12   doc2 と doc6  0.110497\n",
      "26   doc4 と doc7  0.115440\n",
      "33   doc5 と doc9  0.118568\n",
      "4    doc1 と doc6  0.119134\n"
     ]
    }
   ],
   "source": [
    "# jaccard値を小さい順にソート\n",
    "print(ans_jaccard_df.sort_values(by=\"jaccard値\",ascending=True)[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_similarity(set_a, set_b):\n",
    "    num_intersection =  len(set.intersection(set_a, set_b))\n",
    "    sum_nums = len(set_a) + len(set_b)\n",
    "    try:\n",
    "        return 2 * num_intersection / sum_nums\n",
    "    except ZeroDivisionError:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['文書のペア', 'dice値']\n",
    "ans_dice_df = pd.DataFrame(index=[], columns=cols)\n",
    "#Jaccard係数を計算\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i < j:\n",
    "            tmp_name = \"doc\" + str(i+1) + \" と doc\" +  str(j+1)\n",
    "            record = pd.Series([tmp_name, dice_similarity(doc_set_list[i], doc_set_list[j])], index=ans_dice_df.columns)\n",
    "            ans_dice_df = ans_dice_df.append(record, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>文書のペア</th>\n",
       "      <th>dice値</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc1 と doc3</td>\n",
       "      <td>0.305810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc1 と doc4</td>\n",
       "      <td>0.213953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc1 と doc5</td>\n",
       "      <td>0.184397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc1 と doc6</td>\n",
       "      <td>0.212903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         文書のペア     dice値\n",
       "1  doc1 と doc3  0.305810\n",
       "2  doc1 と doc4  0.213953\n",
       "3  doc1 と doc5  0.184397\n",
       "4  doc1 と doc6  0.212903"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_dice_df[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          文書のペア     dice値\n",
      "1   doc1 と doc3  0.305810\n",
      "30  doc5 と doc6  0.297794\n",
      "25  doc4 と doc6  0.291200\n",
      "42  doc8 と doc9  0.286201\n",
      "40  doc7 と doc9  0.278409\n",
      "0   doc1 と doc2  0.272873\n",
      "17  doc3 と doc4  0.270106\n",
      "39  doc7 と doc8  0.269576\n",
      "24  doc4 と doc5  0.267135\n"
     ]
    }
   ],
   "source": [
    "# jaccard値を大きい順にソート\n",
    "print(ans_dice_df.sort_values(by=\"dice値\",ascending=False)[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           文書のペア     dice値\n",
      "3    doc1 と doc5  0.184397\n",
      "31   doc5 と doc7  0.184971\n",
      "11   doc2 と doc5  0.193784\n",
      "16  doc2 と doc10  0.197183\n",
      "43  doc8 と doc10  0.197775\n",
      "12   doc2 と doc6  0.199005\n",
      "26   doc4 と doc7  0.206986\n",
      "33   doc5 と doc9  0.212000\n",
      "4    doc1 と doc6  0.212903\n"
     ]
    }
   ],
   "source": [
    "# jaccard値を大きい順にソート\n",
    "print(ans_dice_df.sort_values(by=\"dice値\",ascending=True)[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Szymkiewicz-Simpson係数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpson_similarity(list_a, list_b):\n",
    "    num_intersection = len(set.intersection(set(list_a), set(list_b)))\n",
    "    min_num = min(len(set(list_a)), len(set(list_b)))\n",
    "    try:\n",
    "        return num_intersection / min_num\n",
    "    except ZeroDivisionError:\n",
    "        if num_intersection == 0:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['文書のペア', 'Szymkiewicz-Simpson']\n",
    "ans_ss_df = pd.DataFrame(index=[], columns=cols)\n",
    "#Jaccard係数を計算\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i < j:\n",
    "            tmp_name = \"doc\" + str(i+1) + \" と doc\" +  str(j+1)\n",
    "            record = pd.Series([tmp_name, simpson_similarity(doc_set_list[i], doc_set_list[j])], index=ans_ss_df.columns)\n",
    "            ans_ss_df = ans_ss_df.append(record, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>文書のペア</th>\n",
       "      <th>Szymkiewicz-Simpson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc1 と doc2</td>\n",
       "      <td>0.280528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc1 と doc3</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc1 と doc4</td>\n",
       "      <td>0.215625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc1 と doc5</td>\n",
       "      <td>0.213115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc1 と doc6</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         文書のペア  Szymkiewicz-Simpson\n",
       "0  doc1 と doc2             0.280528\n",
       "1  doc1 と doc3             0.312500\n",
       "2  doc1 と doc4             0.215625\n",
       "3  doc1 と doc5             0.213115\n",
       "4  doc1 と doc6             0.220000"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_ss_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           文書のペア  Szymkiewicz-Simpson\n",
      "9    doc2 と doc3             0.366337\n",
      "30   doc5 と doc6             0.331967\n",
      "42   doc8 と doc9             0.328125\n",
      "39   doc7 と doc8             0.317221\n",
      "29  doc4 と doc10             0.316923\n",
      "1    doc1 と doc3             0.312500\n",
      "24   doc4 と doc5             0.311475\n",
      "44  doc9 と doc10             0.308594\n",
      "25   doc4 と doc6             0.303333\n"
     ]
    }
   ],
   "source": [
    "# jaccard値を大きい順にソート\n",
    "print(ans_ss_df.sort_values(by=\"Szymkiewicz-Simpson\",ascending=False)[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           文書のペア  Szymkiewicz-Simpson\n",
      "3    doc1 と doc5             0.213115\n",
      "2    doc1 と doc4             0.215625\n",
      "11   doc2 と doc5             0.217213\n",
      "33   doc5 と doc9             0.217213\n",
      "6    doc1 と doc8             0.218750\n",
      "4    doc1 と doc6             0.220000\n",
      "19   doc3 と doc6             0.226667\n",
      "41  doc7 と doc10             0.232143\n",
      "14   doc2 と doc8             0.234323\n"
     ]
    }
   ],
   "source": [
    "# jaccard値を小さい順にソート\n",
    "print(ans_ss_df.sort_values(by=\"Szymkiewicz-Simpson\",ascending=True)[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベクトルベース"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# 形態素解析した文書をTF-IDFを用いてベクトルに変換\n",
    "doc_token_edit = []\n",
    "for doc in doc_token:\n",
    "    doc_token_edit.append('　'.join(doc))\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "tf = vectorizer.fit_transform(doc_token_edit) # 単語の出現頻度を計算\n",
    "tfidf = transformer.fit_transform(tf) # 各ドキュメントのtfidfを計算\n",
    "# print(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベクトルベースの類似度\n",
    "・コサイン類似度  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### コサイン類似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 類似度行列の作成\n",
    "sim = cosine_similarity(tfidf)\n",
    "# df作成\n",
    "cols = ['sim[from][to]', 'cos類似度']\n",
    "cos_df = pd.DataFrame(index=[], columns=cols)\n",
    "for from_id in range(len(doc_list)):\n",
    "    for to_id in range(from_id,len(doc_list)):\n",
    "        if from_id != to_id:\n",
    "            tmp_name = 'sim[{0}][{1}]'.format(from_id+1, to_id+1)\n",
    "            record = pd.Series([tmp_name, sim[from_id][to_id]], index=cos_df.columns)\n",
    "            cos_df = cos_df.append(record, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim[from][to]</th>\n",
       "      <th>cos類似度</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim[1][2]</td>\n",
       "      <td>0.797852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim[1][3]</td>\n",
       "      <td>0.815287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim[1][4]</td>\n",
       "      <td>0.638131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sim[1][5]</td>\n",
       "      <td>0.596893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sim[1][6]</td>\n",
       "      <td>0.520321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sim[1][7]</td>\n",
       "      <td>0.697017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sim[1][8]</td>\n",
       "      <td>0.618456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sim[1][9]</td>\n",
       "      <td>0.620049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sim[1][10]</td>\n",
       "      <td>0.678041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sim[2][3]</td>\n",
       "      <td>0.846432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sim[2][4]</td>\n",
       "      <td>0.657260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sim[2][5]</td>\n",
       "      <td>0.670956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sim[2][6]</td>\n",
       "      <td>0.541325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sim[2][7]</td>\n",
       "      <td>0.748806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sim[2][8]</td>\n",
       "      <td>0.649744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sim[2][9]</td>\n",
       "      <td>0.633849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sim[2][10]</td>\n",
       "      <td>0.719403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sim[3][4]</td>\n",
       "      <td>0.660133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sim[3][5]</td>\n",
       "      <td>0.617000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sim[3][6]</td>\n",
       "      <td>0.512819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sim[3][7]</td>\n",
       "      <td>0.683120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sim[3][8]</td>\n",
       "      <td>0.629747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sim[3][9]</td>\n",
       "      <td>0.653521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sim[3][10]</td>\n",
       "      <td>0.666770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sim[4][5]</td>\n",
       "      <td>0.688775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sim[4][6]</td>\n",
       "      <td>0.551780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sim[4][7]</td>\n",
       "      <td>0.648996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sim[4][8]</td>\n",
       "      <td>0.591831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sim[4][9]</td>\n",
       "      <td>0.569040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sim[4][10]</td>\n",
       "      <td>0.677252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sim[5][6]</td>\n",
       "      <td>0.541178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sim[5][7]</td>\n",
       "      <td>0.644351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sim[5][8]</td>\n",
       "      <td>0.573610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>sim[5][9]</td>\n",
       "      <td>0.534424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sim[5][10]</td>\n",
       "      <td>0.628531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sim[6][7]</td>\n",
       "      <td>0.568450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>sim[6][8]</td>\n",
       "      <td>0.538232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sim[6][9]</td>\n",
       "      <td>0.516926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sim[6][10]</td>\n",
       "      <td>0.582971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sim[7][8]</td>\n",
       "      <td>0.744096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>sim[7][9]</td>\n",
       "      <td>0.690478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sim[7][10]</td>\n",
       "      <td>0.737126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>sim[8][9]</td>\n",
       "      <td>0.719918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sim[8][10]</td>\n",
       "      <td>0.648354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>sim[9][10]</td>\n",
       "      <td>0.616961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sim[from][to]    cos類似度\n",
       "0      sim[1][2]  0.797852\n",
       "1      sim[1][3]  0.815287\n",
       "2      sim[1][4]  0.638131\n",
       "3      sim[1][5]  0.596893\n",
       "4      sim[1][6]  0.520321\n",
       "5      sim[1][7]  0.697017\n",
       "6      sim[1][8]  0.618456\n",
       "7      sim[1][9]  0.620049\n",
       "8     sim[1][10]  0.678041\n",
       "9      sim[2][3]  0.846432\n",
       "10     sim[2][4]  0.657260\n",
       "11     sim[2][5]  0.670956\n",
       "12     sim[2][6]  0.541325\n",
       "13     sim[2][7]  0.748806\n",
       "14     sim[2][8]  0.649744\n",
       "15     sim[2][9]  0.633849\n",
       "16    sim[2][10]  0.719403\n",
       "17     sim[3][4]  0.660133\n",
       "18     sim[3][5]  0.617000\n",
       "19     sim[3][6]  0.512819\n",
       "20     sim[3][7]  0.683120\n",
       "21     sim[3][8]  0.629747\n",
       "22     sim[3][9]  0.653521\n",
       "23    sim[3][10]  0.666770\n",
       "24     sim[4][5]  0.688775\n",
       "25     sim[4][6]  0.551780\n",
       "26     sim[4][7]  0.648996\n",
       "27     sim[4][8]  0.591831\n",
       "28     sim[4][9]  0.569040\n",
       "29    sim[4][10]  0.677252\n",
       "30     sim[5][6]  0.541178\n",
       "31     sim[5][7]  0.644351\n",
       "32     sim[5][8]  0.573610\n",
       "33     sim[5][9]  0.534424\n",
       "34    sim[5][10]  0.628531\n",
       "35     sim[6][7]  0.568450\n",
       "36     sim[6][8]  0.538232\n",
       "37     sim[6][9]  0.516926\n",
       "38    sim[6][10]  0.582971\n",
       "39     sim[7][8]  0.744096\n",
       "40     sim[7][9]  0.690478\n",
       "41    sim[7][10]  0.737126\n",
       "42     sim[8][9]  0.719918\n",
       "43    sim[8][10]  0.648354\n",
       "44    sim[9][10]  0.616961"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sim[from][to]    cos類似度\n",
      "1      sim[1][3]  0.815287\n",
      "0      sim[1][2]  0.797852\n",
      "13     sim[2][7]  0.748806\n",
      "39     sim[7][8]  0.744096\n",
      "41    sim[7][10]  0.737126\n",
      "42     sim[8][9]  0.719918\n",
      "16    sim[2][10]  0.719403\n",
      "5      sim[1][7]  0.697017\n",
      "40     sim[7][9]  0.690478\n"
     ]
    }
   ],
   "source": [
    "#  cos類似度を大きい順にソート\n",
    "print(cos_df.sort_values(by=\"cos類似度\",ascending=False)[1:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
